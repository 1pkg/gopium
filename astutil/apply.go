package astutil

import (
	"bytes"
	"context"
	"go/ast"
	"go/parser"
	"go/printer"
	"go/token"
	"sort"
	"strings"
	"sync"

	"1pkg/gopium"
	"1pkg/gopium/collections"
	"1pkg/gopium/fmtio"

	"golang.org/x/sync/errgroup"
)

// Apply defines abstraction for
// applying custom action
// on original ast package
// accordingly to gopium
// hierarchic collection
type Apply func(
	context.Context,
	*ast.Package,
	gopium.Locator,
	collections.Hierarchic,
) (*ast.Package, error)

// FFN implements apply and combines:
// - fmt with fmtio FSPT helper
// - filter helper
// - note helper
var FFN = combine(
	fmt(fmtio.FSPT),
	filter,
	note,
)

// combine helps to pipe several
// ast helpers to single apply func
func combine(funcs ...Apply) Apply {
	return func(
		ctx context.Context,
		pkg *ast.Package,
		loc gopium.Locator,
		hsts collections.Hierarchic,
	) (*ast.Package, error) {
		// tracks error inside loop
		var err error
		// go through all provided funcs
		for _, fun := range funcs {
			// manage context actions
			// in case of cancelation
			// stop execution
			select {
			case <-ctx.Done():
				return nil, ctx.Err()
			default:
			}
			// exec single func
			pkg, err = fun(ctx, pkg, loc, hsts)
			// in case of any error
			// just propagate it
			if err != nil {
				return nil, err
			}
		}
		return pkg, nil
	}
}

// fmt helps to update ast package
// accordingly to gopium struct result
// using custom fmtio ast formatter
func fmt(sta fmtio.Ast) Apply {
	return func(
		ctx context.Context,
		pkg *ast.Package,
		loc gopium.Locator,
		hsts collections.Hierarchic,
	) (*ast.Package, error) {
		// just reuse inner walk helper
		wpkg, err := walk(ctx, pkg, compid(loc, hsts), wact(sta))
		if err != nil {
			return pkg, err
		}
		// if no error happened
		// just apply format to ast
		return wpkg.(*ast.Package), nil
	}
}

// filter helps to filter structs
// docs and comments from ast type spec
//
// it filters only comments inside
// result structs and autogenerated comments
func filter(
	ctx context.Context,
	pkg *ast.Package,
	loc gopium.Locator,
	hsts collections.Hierarchic,
) (*ast.Package, error) {
	// prepare structs boundaries
	bs := make(collections.Boundaries, 0, len(hsts))
	// collect structs boundaries
	if _, err := walk(
		ctx,
		pkg,
		compid(loc, hsts),
		func(ts *ast.TypeSpec, st gopium.Struct) error {
			// collect structs boundaries
			tts := ts.Type.(*ast.StructType)
			bs = append(bs, collections.Boundary{
				First: tts.Fields.Opening,
				Last:  tts.Fields.Closing,
			})
			return nil
		},
	); err != nil {
		return nil, err
	}
	// create sync error group
	// with cancelation context
	group, gctx := errgroup.WithContext(ctx)
	// go through package files
	for _, file := range pkg.Files {
		// manage context actions
		// in case of cancelation
		// stop execution
		select {
		case <-gctx.Done():
			return pkg, gctx.Err()
		default:
		}
		// capture file copy
		file := file
		group.Go(func() error {
			// go through all file comments
			for _, comments := range file.Comments {
				// prepare comment slice
				comlist := make([]*ast.Comment, 0, len(comments.List))
				// go through comment slice
				for _, com := range comments.List {
					// in case comment has autogenerated prefix skip it
					if strings.Contains(com.Text, gopium.STAMP) {
						continue
					}
					// if comment is inside boundaries skip it
					if bs.Inside(com.Slash) {
						continue
					}
					// otherwise append comment to slice
					comlist = append(comlist, com)
				}
				// update comment list
				comments.List = comlist
			}
			return nil
		})
	}
	return pkg, group.Wait()
}

// note helps to update ast package
// accordingly to gopium struct result
//
// it synchronizes all docs and comments by
// regenerating ast for each file in order
// to update all definitions position
// and ingest docs and comments directly
// to file with correct calculated positions
func note(
	ctx context.Context,
	pkg *ast.Package,
	loc gopium.Locator,
	hsts collections.Hierarchic,
) (*ast.Package, error) {
	// create sync error group
	// with cancelation context
	// and sync map to store updated files
	var files sync.Map
	group, gctx := errgroup.WithContext(ctx)
	// concurently go through package files
	for name, file := range pkg.Files {
		// manage context actions
		// in case of cancelation
		// stop execution
		select {
		case <-gctx.Done():
			return pkg, gctx.Err()
		default:
		}
		// capture name and file copies
		name := name
		file := file
		group.Go(func() error {
			// print ast to buffer
			var buf bytes.Buffer
			if err := printer.Fprint(&buf, loc.Root(), file); err != nil {
				return err
			}
			// parse ast back to file
			// and push child fset to locator
			fset := token.NewFileSet()
			file, err := parser.ParseFile(fset, "", buf.String(), parser.ParseComments)
			if err != nil {
				return err
			}
			loc.Fset(name, fset)
			// go through file structs
			// and note all comments
			comp := comploc(loc, name, hsts)
			wfile, err := walk(gctx, file, compwnote(comp), pressdoc(file))
			if err != nil {
				return err
			}
			// sort all comments by their ast pos
			file = wfile.(*ast.File)
			sort.SliceStable(file.Comments, func(i, j int) bool {
				// sort safe guard
				if len(file.Comments[i].List) == 0 {
					return true
				}
				// sort safe guard
				if len(file.Comments[j].List) == 0 {
					return false
				}
				return file.Comments[i].Pos() < file.Comments[j].Pos()
			})
			// save update file to result map
			files.Store(name, file)
			return nil
		})
	}
	// wait until walk is done
	// in case of any error
	// just return it back
	if err := group.Wait(); err != nil {
		return pkg, err
	}
	// otherwise update ast pkg files
	// with synced files result
	files.Range(func(key interface{}, val interface{}) bool {
		pkg.Files[key.(string)] = val.(*ast.File)
		return true
	})
	return pkg, nil
}
